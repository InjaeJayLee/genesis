{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ad0221-9118-402e-878b-36689961314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GENSIM_DATA_DIR'] = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27d2894e-f4e4-41f9-aba1-dbc884064bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas number format\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b662aac1-0436-4b6b-b8c9-5b18e2ba99b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_size</th>\n",
       "      <th>base_dataset</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fasttext-wiki-news-subwords-300</th>\n",
       "      <td>1005007116</td>\n",
       "      <td>Wikipedia 2017, UMBC webbase corpus and statmt...</td>\n",
       "      <td>{'dimension': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conceptnet-numberbatch-17-06-300</th>\n",
       "      <td>1225497562</td>\n",
       "      <td>ConceptNet, word2vec, GloVe, and OpenSubtitles...</td>\n",
       "      <td>{'dimension': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec-ruscorpora-300</th>\n",
       "      <td>208427381</td>\n",
       "      <td>Russian National Corpus (about 250M words)</td>\n",
       "      <td>{'dimension': 300, 'window_size': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec-google-news-300</th>\n",
       "      <td>1743563840</td>\n",
       "      <td>Google News (about 100 billion words)</td>\n",
       "      <td>{'dimension': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glove-wiki-gigaword-50</th>\n",
       "      <td>69182535</td>\n",
       "      <td>Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)</td>\n",
       "      <td>{'dimension': 50}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file_size  \\\n",
       "fasttext-wiki-news-subwords-300  1005007116   \n",
       "conceptnet-numberbatch-17-06-300 1225497562   \n",
       "word2vec-ruscorpora-300           208427381   \n",
       "word2vec-google-news-300         1743563840   \n",
       "glove-wiki-gigaword-50             69182535   \n",
       "\n",
       "                                                                       base_dataset  \\\n",
       "fasttext-wiki-news-subwords-300   Wikipedia 2017, UMBC webbase corpus and statmt...   \n",
       "conceptnet-numberbatch-17-06-300  ConceptNet, word2vec, GloVe, and OpenSubtitles...   \n",
       "word2vec-ruscorpora-300                  Russian National Corpus (about 250M words)   \n",
       "word2vec-google-news-300                      Google News (about 100 billion words)   \n",
       "glove-wiki-gigaword-50             Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)   \n",
       "\n",
       "                                                             parameters  \n",
       "fasttext-wiki-news-subwords-300                      {'dimension': 300}  \n",
       "conceptnet-numberbatch-17-06-300                     {'dimension': 300}  \n",
       "word2vec-ruscorpora-300           {'dimension': 300, 'window_size': 10}  \n",
       "word2vec-google-news-300                             {'dimension': 300}  \n",
       "glove-wiki-gigaword-50                                {'dimension': 50}  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "info_df = pd.DataFrame.from_dict(api.info()['models'], orient='index')\n",
    "info_df[['file_size', 'base_dataset', 'parameters']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc56439-8337-446d-a36a-a15daa26f36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================---------------------------------] 35.5% 23.4/66.0MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================================----] 92.7% 61.2/66.0MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d93c0be-883b-4991-8036-4d74c9fc92f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector size: 50\n",
      "v_king  = [ 0.50451   0.68607  -0.59517  -0.022801  0.60046  -0.13498  -0.08813\n",
      "  0.47377  -0.61798  -0.31012 ]\n",
      "v_queen = [ 0.37854   1.8233   -1.2648   -0.1043    0.35829   0.60029  -0.17538\n",
      "  0.83767  -0.056798 -0.75795 ]\n",
      "similarity: 0.7839043\n"
     ]
    }
   ],
   "source": [
    "v_king = model['king']\n",
    "v_queen = model['queen']\n",
    "\n",
    "print(\"Vector size:\", model.vector_size)\n",
    "print(\"v_king  =\", v_king[:10])\n",
    "print(\"v_queen =\", v_queen[:10])\n",
    "print(\"similarity:\", model.similarity('king', 'queen'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d794e4-9298-4329-ae08-df9646c9a0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 0.8236179947853088),\n",
       " ('queen', 0.7839042544364929),\n",
       " ('ii', 0.7746230363845825)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('king', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8debf784-af27-404e-8d39-06542ceb53e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78390425,  0.47800115, -0.25490996], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_lion = model['lion']\n",
    "v_nano = model['nanotechnology']\n",
    "\n",
    "model.cosine_similarities(v_king, [v_queen, v_lion, v_nano])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14df827-5e3b-441e-904e-dc51ef7a69ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.8523604273796082),\n",
       " ('throne', 0.7664334177970886),\n",
       " ('prince', 0.7592144012451172)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bbc47e4-c39d-4b64-b2ef-fa8c29f0e2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('berlin', 0.9203965663909912),\n",
       " ('frankfurt', 0.8201637268066406),\n",
       " ('vienna', 0.8182449340820312)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['paris', 'germany'], negative=['france'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed6a1dc1-a90f-4443-9c82-2d4a17ade4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paris', 0.7835100293159485)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['france', 'capital'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb79aba6-fba0-42d4-af24-fff4adc42586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('central', 0.7972516417503357),\n",
       " ('western', 0.7565553188323975),\n",
       " ('region', 0.7500612735748291)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['greece', 'capital'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a2e88ea-01f9-417a-9652-d976c90855c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "756ae689-98a8-41d6-a761-cbab0b23eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"./data/reddit-selfposts-ch10.db\"\n",
    "con = sqlite3.connect(db_name)\n",
    "df = pd.read_sql(\"select subreddit, lemmas, text from posts_nlp\", con)\n",
    "con.close()\n",
    "\n",
    "df['lemmas'] = df['lemmas'].str.lower().str.split() # lower case tokens\n",
    "sents = df['lemmas'] # our training \"sentences\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c96ebc5a-f367-4541-be6e-ac5d121ee3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, npmi_scorer\n",
    "import gensim\n",
    "\n",
    "# solved compatibility issue for Gensim 4.x\n",
    "if gensim.__version__[0] > '3': # gensim 4.x string delimiter\n",
    "    delim = '-'\n",
    "else: # gensim 3.x - byte delimiter\n",
    "    delim = b'-'\n",
    "\n",
    "phrases = Phrases(sents, min_count=10, threshold=0.3, \n",
    "                  delimiter=delim, scoring=npmi_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f86abc0e-3af3-4369-a862-cda5e4ef3c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I|had|to|replace|the|timing-belt|in|my|mercedes-c300\n"
     ]
    }
   ],
   "source": [
    "sent = \"I had to replace the timing belt in my mercedes c300\".split()\n",
    "phrased = phrases[sent]\n",
    "print('|'.join(phrased))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffb19b4f-c568-493e-8ccb-47ca8a6382d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solved compatibility issue for Gensim 4.x\n",
    "if gensim.__version__[0] > '3': # gensim 4.x - find_phrases / string phrases\n",
    "\n",
    "    phrase_df = pd.DataFrame(phrases.find_phrases(sents), \n",
    "                             columns =['phrase', 'score'])\n",
    "    phrase_df = pd.DataFrame.from_dict(phrases.find_phrases(sents), orient='index').reset_index()\n",
    "    phrase_df.columns = ['phrase', 'score']\n",
    "    phrase_df = phrase_df[['phrase', 'score']].drop_duplicates() \\\n",
    "            .sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "else: # gensim 3.x - export_phrases / byte phrases\n",
    "    phrase_df = pd.DataFrame(phrases.export_phrases(sents, out_delimiter=delim), \n",
    "                             columns =['phrase', 'score'])\n",
    "    phrase_df = phrase_df[['phrase', 'score']].drop_duplicates() \\\n",
    "        .sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "    phrase_df['phrase'] = phrase_df['phrase'].map(lambda p: p.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04ee8dda-d330-49ce-8959-98518f1e5a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>mercedes-c300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             phrase  score\n",
       "83    mercedes-benz      1\n",
       "1416  mercedes-c300      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_df[phrase_df['phrase'].str.contains('mercedes')] .head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44aab0f1-1624-4543-9437-a26249fbda50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>c-class</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>intake-manifold</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>z-axi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>panoramic-sunroof</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>west-coast</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>keyless-entry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>american-muscle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>horror-story</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>acura-tl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>roush-axleback</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                phrase  score\n",
       "152            c-class      1\n",
       "182    intake-manifold      1\n",
       "98               z-axi      1\n",
       "231  panoramic-sunroof      1\n",
       "207         west-coast      1\n",
       "..                 ...    ...\n",
       "35       keyless-entry      1\n",
       "95     american-muscle      1\n",
       "86        horror-story      1\n",
       "120           acura-tl      1\n",
       "115     roush-axleback      1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_df.query('score > 0.7').sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "026116bf-e5be-44ca-a855-8e3b8e7a537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(sents, min_count=10, threshold=0.7, \n",
    "                  delimiter=delim, scoring=npmi_scorer)\n",
    "\n",
    "df['phrased_lemmas'] = df['lemmas'].map(lambda s: phrases[s])\n",
    "sents = df['phrased_lemmas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af6b1fa3-0c77-4b9a-907a-4f7ab3ba272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sents,           # tokenized input sentences\n",
    "                 vector_size=100, # size of word vectors (default 100)\n",
    "                 window=2,        # context window size (default 5)\n",
    "                 sg=1,            # use skip-gram (default 0 = CBOW)\n",
    "                 negative=5,      # number of negative samples (default 5)\n",
    "                 min_count=5,     # ignore infrequent words (default 5)\n",
    "                 workers=4,       # number of threads (default 3)\n",
    "                 epochs=5)         # number of epochs (default 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
