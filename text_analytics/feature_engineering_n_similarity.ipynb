{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb033500-8c36-4d94-920a-bc55ba437973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['foolishness', 0],\n",
       " ['times', 1],\n",
       " ['wisdom', 2],\n",
       " ['worst', 3],\n",
       " ['age', 4],\n",
       " ['it', 5],\n",
       " ['best', 6],\n",
       " ['of', 7],\n",
       " ['It', 8],\n",
       " ['was', 9],\n",
       " ['the', 10]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"It was the best of times\", \n",
    "             \"it was the worst of times\", \n",
    "             \"it was the age of wisdom\", \n",
    "             \"it was the age of foolishness\"]\n",
    "\n",
    "tokenized_sentences = [[t for t in sentence.split()] for sentence in sentences]\n",
    "\n",
    "vocabulary = set([w for s in tokenized_sentences for w in s])\n",
    "\n",
    "import pandas as pd\n",
    "[[w, i] for i,w in enumerate(vocabulary)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d6e573c-e285-4c63-9e84-aa39a0955609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1]: It was the best of times\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1]: it was the worst of times\n",
      "[0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1]: it was the age of wisdom\n",
      "[1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1]: it was the age of foolishness\n"
     ]
    }
   ],
   "source": [
    "def onehot_encode(tokenized_sentence):\n",
    "    return [1 if w in tokenized_sentence else 0 for w in vocabulary]\n",
    "\n",
    "onehot = [onehot_encode(tokenized_sentence) for tokenized_sentence in tokenized_sentences]\n",
    "\n",
    "for (sentence, oh) in zip(sentences, onehot):\n",
    "    print(\"%s: %s\" % (oh, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535312a5-318f-48d2-9440-bd261a19f5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'It',\n",
       " 'age',\n",
       " 'best',\n",
       " 'foolishness',\n",
       " 'it',\n",
       " 'of',\n",
       " 'the',\n",
       " 'times',\n",
       " 'was',\n",
       " 'wisdom',\n",
       " 'worst'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1992a04-c3a2-4c10-9a3a-6320404b09f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foolishness</th>\n",
       "      <th>times</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "      <th>age</th>\n",
       "      <th>it</th>\n",
       "      <th>best</th>\n",
       "      <th>of</th>\n",
       "      <th>It</th>\n",
       "      <th>was</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   foolishness  times  wisdom  worst  age  it  best  of  It  was  the\n",
       "0            0      1       0      0    0   0     1   1   1    1    1\n",
       "1            0      1       0      1    0   1     0   1   0    1    1\n",
       "2            0      0       1      0    1   1     0   1   0    1    1\n",
       "3            1      0       0      0    1   1     0   1   0    1    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(onehot, columns=list(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6546d756-0195-4b1f-a61d-99d588b6fa51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = [onehot[0][i] & onehot[1][i] for i in range(0, len(vocabulary))]\n",
    "sum(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "530cf255-67d7-48dd-95cc-d7103a05cc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.dot(onehot[0], onehot[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3970584a-718d-4dac-ab0a-6240c66293ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       " [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1],\n",
       " [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1],\n",
       " [1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7ddcafa-6878-4f48-8564-feb7ebcb5b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1],\n",
       "       [1, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec649f74-9508-412b-9e8e-e6020d7ed88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 4, 3, 3],\n",
       "       [4, 6, 4, 4],\n",
       "       [3, 4, 6, 5],\n",
       "       [3, 4, 5, 6]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(onehot, np.transpose(onehot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf6a312-d240-4494-a815-b0fe2358ef21",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 단어 가방 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec0c2cff-93b3-44a2-919b-1287b6c331b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6d4706d-4f9c-4383-8d68-e4807f8c4d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It was the best of times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it was the worst of times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it was the age of wisdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was the age of foolishness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John likes to watch movies. Mary likes movies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mary also likes to watch football games.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                           It was the best of times\n",
       "1                          it was the worst of times\n",
       "2                           it was the age of wisdom\n",
       "3                      it was the age of foolishness\n",
       "4  John likes to watch movies. Mary likes movies ...\n",
       "5           Mary also likes to watch football games."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_sentences = sentences + [\"John likes to watch movies. Mary likes movies too.\",\n",
    "                              \"Mary also likes to watch football games.\"]\n",
    "pd.DataFrame(more_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1930d8d1-fb1e-496c-8fa7-2a161a03d75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(more_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64a1b126-d867-4358-bbe8-0a5b3d665913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' 'also' 'best' 'foolishness' 'football' 'games' 'it' 'john' 'likes'\n",
      " 'mary' 'movies' 'of' 'the' 'times' 'to' 'too' 'was' 'watch' 'wisdom'\n",
      " 'worst']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d635b00-c859-4023-afa3-13cf1fcdd1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=cv.transform(more_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "847112a0-a081-43ce-82d5-379728b6dc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9673287-8734-459e-9391-5a2d06bea850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>also</th>\n",
       "      <th>best</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>football</th>\n",
       "      <th>games</th>\n",
       "      <th>it</th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>mary</th>\n",
       "      <th>movies</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>times</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>was</th>\n",
       "      <th>watch</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  also  best  foolishness  football  games  it  john  likes  mary  \\\n",
       "0    0     0     1            0         0      0   1     0      0     0   \n",
       "1    0     0     0            0         0      0   1     0      0     0   \n",
       "2    1     0     0            0         0      0   1     0      0     0   \n",
       "3    1     0     0            1         0      0   1     0      0     0   \n",
       "4    0     0     0            0         0      0   0     1      2     1   \n",
       "5    0     1     0            0         1      1   0     0      1     1   \n",
       "\n",
       "   movies  of  the  times  to  too  was  watch  wisdom  worst  \n",
       "0       0   1    1      1   0    0    1      0       0      0  \n",
       "1       0   1    1      1   0    0    1      0       0      1  \n",
       "2       0   1    1      0   0    0    1      0       1      0  \n",
       "3       0   1    1      0   0    0    1      0       0      0  \n",
       "4       2   0    0      0   1    1    0      1       0      0  \n",
       "5       0   0    0      0   1    0    0      1       0      0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dt.toarray(), columns=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6946011-57f3-4727-99c8-463abcde7ec1",
   "metadata": {},
   "source": [
    "단어 가방모델을 이용해 문서간의 유사성 계산: 벡터간의 각도를 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ceb76525-a253-4b67-8bb4-9298bc8f6518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83333333]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(dt[0], dt[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c200cdaa-86ca-4ffb-afe8-01ffb3adee74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.524142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524142</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0  1.000000  0.833333  0.666667  0.666667  0.000000  0.000000\n",
       "1  0.833333  1.000000  0.666667  0.666667  0.000000  0.000000\n",
       "2  0.666667  0.666667  1.000000  0.833333  0.000000  0.000000\n",
       "3  0.666667  0.666667  0.833333  1.000000  0.000000  0.000000\n",
       "4  0.000000  0.000000  0.000000  0.000000  1.000000  0.524142\n",
       "5  0.000000  0.000000  0.000000  0.000000  0.524142  1.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cosine_similarity(dt, dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c81dfc-b9dc-4f36-8926-4f123c1647a6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## TF-IDF 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad759c99-2f32-4e78-b628-7e657868d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37100d4f-903d-4f5f-a0d2-77d887864c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>also</th>\n",
       "      <th>best</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>football</th>\n",
       "      <th>games</th>\n",
       "      <th>it</th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>mary</th>\n",
       "      <th>movies</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>times</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>was</th>\n",
       "      <th>watch</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.56978</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.467228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.467228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.56978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.467228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.56978</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.467228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.56978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305609</td>\n",
       "      <td>0.501208</td>\n",
       "      <td>0.250604</td>\n",
       "      <td>0.611219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250604</td>\n",
       "      <td>0.305609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250604</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419233</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.419233</td>\n",
       "      <td>0.419233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343777</td>\n",
       "      <td>0.343777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343777</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age      also     best  foolishness  football     games        it  \\\n",
       "0  0.000000  0.000000  0.56978      0.00000  0.000000  0.000000  0.338027   \n",
       "1  0.000000  0.000000  0.00000      0.00000  0.000000  0.000000  0.338027   \n",
       "2  0.467228  0.000000  0.00000      0.00000  0.000000  0.000000  0.338027   \n",
       "3  0.467228  0.000000  0.00000      0.56978  0.000000  0.000000  0.338027   \n",
       "4  0.000000  0.000000  0.00000      0.00000  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.419233  0.00000      0.00000  0.419233  0.419233  0.000000   \n",
       "\n",
       "       john     likes      mary    movies        of       the     times  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.338027  0.338027  0.467228   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.338027  0.338027  0.467228   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.338027  0.338027  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.338027  0.338027  0.000000   \n",
       "4  0.305609  0.501208  0.250604  0.611219  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.343777  0.343777  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         to       too       was     watch   wisdom    worst  \n",
       "0  0.000000  0.000000  0.338027  0.000000  0.00000  0.00000  \n",
       "1  0.000000  0.000000  0.338027  0.000000  0.00000  0.56978  \n",
       "2  0.000000  0.000000  0.338027  0.000000  0.56978  0.00000  \n",
       "3  0.000000  0.000000  0.338027  0.000000  0.00000  0.00000  \n",
       "4  0.250604  0.305609  0.000000  0.250604  0.00000  0.00000  \n",
       "5  0.343777  0.000000  0.000000  0.343777  0.00000  0.00000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "tfidf_dt = tfidf.fit_transform(dt)\n",
    "pd.DataFrame(tfidf_dt.toarray(), columns=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b51f66a-f86d-4c91-98e6-70a304fb6e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.675351</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.675351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.675351</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>0.675351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.43076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.43076</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3        4        5\n",
       "0  1.000000  0.675351  0.457049  0.457049  0.00000  0.00000\n",
       "1  0.675351  1.000000  0.457049  0.457049  0.00000  0.00000\n",
       "2  0.457049  0.457049  1.000000  0.675351  0.00000  0.00000\n",
       "3  0.457049  0.457049  0.675351  1.000000  0.00000  0.00000\n",
       "4  0.000000  0.000000  0.000000  0.000000  1.00000  0.43076\n",
       "5  0.000000  0.000000  0.000000  0.000000  0.43076  1.00000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cosine_similarity(tfidf_dt, tfidf_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65b76684-9132-4b7c-88ef-d46be46f0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = pd.read_csv(\"./data/abcnews-date-text.csv\", parse_dates=[\"publish_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d49e896-cd23-4b18-978c-fc488657154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103663\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publish_date                                      headline_text\n",
       "0   2003-02-19  aba decides against community broadcasting lic...\n",
       "1   2003-02-19     act fire witnesses must be aware of defamation\n",
       "2   2003-02-19     a g calls for infrastructure protection summit\n",
       "3   2003-02-19           air nz staff in aust strike for pay rise\n",
       "4   2003-02-19      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(headlines))\n",
    "headlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fc04254-3810-4817-902b-24aee2755267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "dt=tfidf.fit_transform(headlines[\"headline_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9c30849-c82c-4063-8813-00ef56eb423f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1103663x95878 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7001357 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4d91221-cabb-4183-a115-50431b9d0a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 297 ms\n",
      "Wall time: 532 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.16913596,\n",
       "        0.16792138],\n",
       "       [0.        , 0.        , 0.        , ..., 0.16913596, 1.        ,\n",
       "        0.33258708],\n",
       "       [0.        , 0.        , 0.        , ..., 0.16792138, 0.33258708,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cosine_similarity(dt[0:10000], dt[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "420ae0fe-81b9-466f-a435-1bb8d66b9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a845823c-3ae7-42f6-af20-cfee79d83c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d8eb13c-b87f-4246-a539-784d05d9324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\study\\genesis\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1103663x95600 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5644186 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=list(stopwords))\n",
    "dt = tfidf.fit_transform(headlines[\"headline_text\"])\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f65da6e9-0bde-4dab-9144-4ca1298e2fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1103663x58527 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5607113 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=list(stopwords), min_df=2)\n",
    "dt = tfidf.fit_transform(headlines[\"headline_text\"])\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff984b35-b4fc-4694-bf6d-b914f818fdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1103663x6772 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4816381 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=list(stopwords), min_df=0.0001)\n",
    "dt = tfidf.fit_transform(headlines[\"headline_text\"])\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "037b13e0-e66f-434a-8e15-639684f821f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1103663x95600 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5644186 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=list(stopwords), max_df=0.1)\n",
    "dt = tfidf.fit_transform(headlines[\"headline_text\"])\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "053a3086-0617-46c4-ae01-363fe5165f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1103663/1103663 [44:46<00:00, 410.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nouns_adjectives_verbs = [\"NOUN\", \"PROPN\", \"ADJ\", \"ADV\", \"VERB\"]\n",
    "for i, row in tqdm(headlines.iterrows(), total=len(headlines)):\n",
    "    doc = nlp(str(row[\"headline_text\"]))\n",
    "    headlines.at[i, \"lemmas\"] = \" \".join([token.lemma_ for token in doc])\n",
    "    headlines.at[i, \"nav\"] = \" \".join([token.lemma_ for token in doc if token.pos_ in nouns_adjectives_verbs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4dc9c15f-4799-4c23-8557-f72669312f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>nav</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "      <td>aba decide against community broadcasting licence</td>\n",
       "      <td>aba decide community broadcasting licence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "      <td>act fire witness must be aware of defamation</td>\n",
       "      <td>act fire witness aware defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "      <td>a g call for infrastructure protection summit</td>\n",
       "      <td>g call infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "      <td>air nz staff aust strike pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "      <td>air nz strike to affect australian traveller</td>\n",
       "      <td>air nz strike affect australian traveller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103658</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>the ashes smiths warners near miss liven up bo...</td>\n",
       "      <td>the ashe smith warner near miss liven up box d...</td>\n",
       "      <td>ashe smith warner miss liven box day test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103659</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>timelapse: brisbanes new year fireworks</td>\n",
       "      <td>timelapse : brisbane new year firework</td>\n",
       "      <td>timelapse brisbane new year firework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103660</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>what 2017 meant to the kids of australia</td>\n",
       "      <td>what 2017 mean to the kid of australia</td>\n",
       "      <td>mean kid australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103661</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>what the papodopoulos meeting may mean for ausus</td>\n",
       "      <td>what the papodopoulos meeting may mean for ausus</td>\n",
       "      <td>papodopoulos meeting mean ausus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103662</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>who is george papadopoulos the former trump ca...</td>\n",
       "      <td>who be george papadopoulos the former trump ca...</td>\n",
       "      <td>george papadopoulos former trump campaign aide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1103663 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        publish_date                                      headline_text  \\\n",
       "0         2003-02-19  aba decides against community broadcasting lic...   \n",
       "1         2003-02-19     act fire witnesses must be aware of defamation   \n",
       "2         2003-02-19     a g calls for infrastructure protection summit   \n",
       "3         2003-02-19           air nz staff in aust strike for pay rise   \n",
       "4         2003-02-19      air nz strike to affect australian travellers   \n",
       "...              ...                                                ...   \n",
       "1103658   2017-12-31  the ashes smiths warners near miss liven up bo...   \n",
       "1103659   2017-12-31            timelapse: brisbanes new year fireworks   \n",
       "1103660   2017-12-31           what 2017 meant to the kids of australia   \n",
       "1103661   2017-12-31   what the papodopoulos meeting may mean for ausus   \n",
       "1103662   2017-12-31  who is george papadopoulos the former trump ca...   \n",
       "\n",
       "                                                    lemmas  \\\n",
       "0        aba decide against community broadcasting licence   \n",
       "1             act fire witness must be aware of defamation   \n",
       "2            a g call for infrastructure protection summit   \n",
       "3                 air nz staff in aust strike for pay rise   \n",
       "4             air nz strike to affect australian traveller   \n",
       "...                                                    ...   \n",
       "1103658  the ashe smith warner near miss liven up box d...   \n",
       "1103659             timelapse : brisbane new year firework   \n",
       "1103660             what 2017 mean to the kid of australia   \n",
       "1103661   what the papodopoulos meeting may mean for ausus   \n",
       "1103662  who be george papadopoulos the former trump ca...   \n",
       "\n",
       "                                                    nav  \n",
       "0             aba decide community broadcasting licence  \n",
       "1                     act fire witness aware defamation  \n",
       "2               g call infrastructure protection summit  \n",
       "3                     air nz staff aust strike pay rise  \n",
       "4             air nz strike affect australian traveller  \n",
       "...                                                 ...  \n",
       "1103658       ashe smith warner miss liven box day test  \n",
       "1103659            timelapse brisbane new year firework  \n",
       "1103660                              mean kid australia  \n",
       "1103661                 papodopoulos meeting mean ausus  \n",
       "1103662  george papadopoulos former trump campaign aide  \n",
       "\n",
       "[1103663 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80ead2-6e55-436b-91fa-f4c25c9b9a2d",
   "metadata": {},
   "source": [
    "### 원형을 사용한 문서 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19407421-da80-4d9f-9b0c-de62dc307171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\study\\genesis\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1103663x82761 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5546562 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=list(stopwords))\n",
    "dt = tfidf.fit_transform(headlines[\"lemmas\"].map(str))\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c48d797-b926-4c2d-bbd3-b9787213b361",
   "metadata": {},
   "source": [
    "### 단어 유형 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a58ef206-0415-4a53-9ccc-80343db49c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1103663x79759 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5443874 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=list(stopwords))\n",
    "dt = tfidf.fit_transform(headlines[\"nav\"].map(str))\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64170b-42e1-4601-97d2-cd6b9327c387",
   "metadata": {},
   "source": [
    "### 일반 단어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7bb30f34-6d87-49c9-8bc3-2ac25607d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10000 = pd.read_csv(\"https://raw.githubusercontent.com/first20hours/google-10000-english/master/google-10000-english.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d7b8dbb5-4437-489e-b0e0-39ee72b914ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\study\\genesis\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1103663x559961 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8415675 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=list(stopwords), ngram_range=(1,2), min_df=2)\n",
    "dt = tfidf.fit_transform(headlines[\"headline_text\"])\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b1ca2cb1-31ab-4cfc-8941-a12aae4486ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1103663x747988 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9045013 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=list(stopwords), ngram_range=(1,3), min_df=2)\n",
    "dt = tfidf.fit_transform(headlines[\"headline_text\"])\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ab5b413-c549-428f-b89f-3c591efbd20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1103663x94689 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1531237 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=list(top_10000.iloc[:,0].values), ngram_range=(1,2), min_df=2)\n",
    "dt = tfidf.fit_transform(headlines[\"nav\"].map(str))\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da8501-c4ac-4902-a541-6425a61979ac",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 구문 유사성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d9caa84-c136-41a0-89e6-a0acc6ac83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어와 바이그램을 이용한 벡터화\n",
    "stopwords.add(\"test\")\n",
    "tfidf = TfidfVectorizer(stop_words=list(stopwords), ngram_range=(1,2), min_df=2, norm='l2')\n",
    "dt = tfidf.fit_transform(headlines[\"headline_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dce4bd97-d4dc-452c-a88c-17da40b0851c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1103663x559346 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8405225 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "443cbb77-1e91-46b0-8cf7-e83db047603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "made_up = tfidf.transform([\"australia and new zealand discuss optimal apple size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3ad254ae-438e-422b-8414-56cd9ff3a308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publish_date                                2014-05-09 00:00:00\n",
       "headline_text    call for australia and new zealand to give job\n",
       "lemmas           call for australia and new zealand to give job\n",
       "nav                         call australia new zealand give job\n",
       "Name: 873886, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = cosine_similarity(made_up, dt)\n",
    "headlines.iloc[np.argmax(sim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a8ffb157-e7c7-4639-885b-abc55df645aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 59.4 s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch = 10000\n",
    "max_sim = 0.0\n",
    "max_a = None\n",
    "max_b = None\n",
    "for a in range(0, dt.shape[0], batch):\n",
    "    for b in range(0, a+batch, batch):\n",
    "        r = np.dot(dt[a:a+batch], np.transpose(dt[b:b+batch]))\n",
    "        r[r > 0.9999] = np.nan\n",
    "        sim = r.max()\n",
    "        if sim > max_sim:\n",
    "            (max_a, max_b) = np.unravel_index(np.argmax(r), r.shape)\n",
    "            max_a += a\n",
    "            max_b += b\n",
    "            max_sim = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b93dec3c-aff4-4e7a-bf55-d436f97fe615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985505841515539 904965 364042\n"
     ]
    }
   ],
   "source": [
    "print(max_sim, max_a, max_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e1f6c33b-339b-4855-8d44-07d5415fc107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_date                                2014-09-18 00:00:00\n",
      "headline_text    vline fails to meet punctuality targets report\n",
      "lemmas             vline fail to meet punctuality target report\n",
      "nav                   vline fail meet punctuality target report\n",
      "Name: 904965, dtype: object\n",
      "publish_date                         2008-02-15 00:00:00\n",
      "headline_text    vline fails to meet punctuality targets\n",
      "lemmas             vline fail to meet punctuality target\n",
      "nav                   vline fail meet punctuality target\n",
      "Name: 364042, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(headlines.iloc[max_a])\n",
    "print(headlines.iloc[max_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ef1bf-cde8-4a2d-a6da-f4889d81da1c",
   "metadata": {},
   "source": [
    "### 관련 단어 탐색 (문서-용어 행렬 대신 용어-문서 행렬을 이용 -> 열벡터를 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "761a81f0-edd3-4b6e-8247-26ced77e2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_word = TfidfVectorizer(stop_words=list(stopwords), min_df=1000)\n",
    "dt_word = tfidf_word.fit_transform(headlines[\"headline_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5fa7a21a-d43b-4a54-9552-ea9f2de62147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1103663x1132 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2980495 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "44ec5edd-830e-462f-973a-3eff3c453fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = cosine_similarity(dt_word.T, dt_word.T)\n",
    "np.fill_diagonal(r, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bd6004ea-f9a3-4995-8a9f-49e20ecf29f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sri related to lanka\n",
      "hour related to country\n",
      "seekers related to asylum\n",
      "springs related to alice\n",
      "pleads related to guilty\n",
      "hill related to broken\n",
      "trump related to donald\n",
      "violence related to domestic\n",
      "climate related to change\n",
      "driving related to drink\n",
      "care related to aged\n",
      "gold related to coast\n",
      "royal related to commission\n",
      "mental related to health\n",
      "wind related to farm\n",
      "flu related to bird\n",
      "murray related to darling\n",
      "world related to cup\n",
      "north related to korea\n",
      "hour related to 2014\n"
     ]
    }
   ],
   "source": [
    "# 유사도가 가장 큰 항목 찾기\n",
    "# 1차원배열로 변환 후 np.argsort를 통해 정렬된 요소의 인덱스를 가져오고 어휘 조회를 위해 원래 인덱스를 복원\n",
    "voc = tfidf_word.get_feature_names_out()\n",
    "size = r.shape[0]\n",
    "for index in np.argsort(r.flatten())[::-1][0:40]:\n",
    "    a = int(index / size)\n",
    "    b = index % size\n",
    "    if a > b:\n",
    "        print(f'{voc[a]} related to {voc[b]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
